\chapter{CD Content}

\begin{table}[h]
	\centering
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{|l|l|}
		\hline
		Directory & Content  \\
		\hline
		\hline
		captioning/ & Torch scripts for full model training. \\
		captioning/pretrainRNN/ & Tools for pretraining language model. \\
		captioning/bagOfWords/ & Tools for experiments with bag of words input. \\
		text/ & \LaTeX\ source of this text. \\
		text/fig/ & Figures used in this text. \\
		video/ & Video presenting the work. \\
		\hline
	\end{tabular}
	\label{tab:cdcontent}
\end{table}

\chapter{\gls{coco} Annotation format} \label{chp:jsonAnnotation}
\begin{lstlisting}[language=json,firstnumber=1]
	{
		"info"		: info,
		"images"		: [image],
		"annotations"	: [annotation],
		"licenses"	: [license]
	}
	info {
		"year"		: int,
		"version"	: str,
		"description"	: str,
		"contributor"	: str,
		"url"		: str,
		"date_created"	: datetime
	}
	image {
		"id"		: int,
		"width"		: int,
		"height"		: int,
		"file_name"	: str,
		"license"	: int,
		"flickr_url"	: str,
		"coco_url"	: str,
		"date_captured"	: datetime
	}
	license {
		"id"		: int,
		"name"		: str,
		"url"		: str
	}
	annotation {
		"id"		: int,
		"image_id"	: int,
		"caption"	: str
	}
\end{lstlisting}

\chapter{Installing Torch}\label{chp:installation}

\begin{lstlisting}[firstnumber=1,breakindent=75pt, language=bash,frame=single]
# in a terminal, run the commands WITHOUT sudo
git clone https://github.com/torch/distro.git ~/torch --recursive
cd ~/torch; bash install-deps;
./install.sh

# activate Torch in current shell
. ~/torch/install/bin/torch-activate

# reinstall basic nn package
luarocks remove nn
luarocks install nn

# install necessary packages
luarocks install cunn
luarocks install cunnx
luarocks install rnn
luarocks install tds
luarocks install image

\end{lstlisting}

\chapter{Scripts Manuals} \label{chp:manuals}

\section{RNN pretraining}

\subsubsection{Training}

\begin{lstlisting}[firstnumber=1,breakindent=75pt]
~/captioning/pretrainRNN$ th training.lua --help  
Usage: th [options] 

Train a RNN language model for generating image captions.

Options
-captionFile    JSON file with the input data (captions, image names). [~/COCO/captions_train2014.json]

-recurLayers    Number of recurrent layers. (At least one.) [3]
-hiddenUnits    Number of units in hidden layers. (At least one.) [300]
-dropout        Use dropout. [false]
-batchSize      Minibatch size. [15]
-printError     Print error once per N minibatches. [10]
-sample         Try to sample once per N minibatches. [100]
-saveModel      Save model once per N minibatches. [10000]
-modelName      Filename of the model and training data. [rnn.torch]
-modelDirectory Directory where to save the model. [~/RNN/]
\end{lstlisting}
\hspace{1cm}

\subsubsection{Sampling}

\begin{lstlisting}[firstnumber=1,breakindent=75pt]
~/captioning/pretrainRNN$ th sampling.lua --help
Usage: th [options] 

Sample a language model for generating image captions.

Options
-modelName Filename of the model and training data. [~/RNN/rnn.torch]
-N         How many captions will be generated. [4]
\end{lstlisting}
\hspace{1cm}

\section{Full model}

\subsubsection{Training}

\begin{lstlisting}[firstnumber=1,breakindent=75pt]
~/captioning$ th training.lua --help
Usage: th [options] 

Training of the CNN-RNN network for generating image captions.

Options
-captionFile    JSON file with the input data (captions, image names). [~/COCO/captions_train2014.json]
-imageDirectory Directory with the images named according to the caption file. [~/COCO/train2014/]

-pretrainedCNN  Path to a ImageNet pretrained CNN in Torch format. [~/CNN/VGG_ILSVRC_16_layers_fc7.torch]
-ft             Finetune CNN on the dataset. (Enable CNN training.) [false]

-pretrainedRNN  Path to a pretrained RNN. [~/RNN/2.0000__3x300.torch]

-rnnLayers      If no RNN is provided, number of recurrent layers while creating RNN. (At least one.) [3]
-rnnHidden      If no RNN is provided, number of units in hidden layers while creating RNN. (At least one.) [300]
-rnnDropout     If no RNN is provided, use dropout while creating RNN. [false]

-initLayers     How many reccurent layers initialize with CNN data. (0 - all of them) [0]
-batchSize      Minibatch size. [15]
-printError     Print error once per N minibatches. [10]
-sample         Try to sample once per N minibatches. [100]
-saveModel      Save model once per N minibatches. [10000]
-modelName      File name of the saved or loaded model and training data. [model.torch]
-modelDirectory Directory where to save the model. [~/combined_model/]
\end{lstlisting}
\hspace{1cm}

\subsubsection{Sampling}

\begin{lstlisting}[firstnumber=1,breakindent=75pt]
~/captioning$ th sampling.lua --help
Usage: th [options] 

Generate captions for images with trained model.

Options
-modelName Name of the model to be loaded. [model.torch]
-N         How many captions will be generated. [3]
\end{lstlisting}
\hspace{1cm}

\section{Bag of Words models}

\subsubsection{Training}

\begin{lstlisting}[firstnumber=1,breakindent=75pt]
~/captioning/bagOfWords$ th training.lua --help
Usage: th [options] 

Training of the RNN network for generating image captions initialized with bag of words.

Options
-captionFile    JSON file with the input data (captions, image names). [~/COCO/captions_train2014.json]
-imageDirectory Directory with the images with names according to the caption file. [~/COCO/train2014/]

-pretrainedRNN  Path to a pretrained RNN. [~/RNN/2.0000__3x300.torch]

-rnnLayers      If no RNN is provided, number of recurrent layers while creating RNN. (At least one.) [3]
-rnnHidden      If no RNN is provided, number of units in hidden layers while creating RNN. (At least one.) [300]
-rnnDropout     If no RNN is provided, use dropout while creating RNN. [false]

-initLayers     How many reccurent layers initialize with CNN data. (0 - all of them) [0]
-batchSize      Minibatch size. [15]
-printError     Print error once per N minibatches. [10]
-sample         Try to sample once per N minibatches. [100]
-saveModel      Save model once per N minibatches. [10000]
-modelName      File name of the saved or loaded model and training data. [model_bag.torch]
-modelDirectory Directory where to save the model. [~/combined_model/]
\end{lstlisting}
\hspace{1cm}

\subsubsection{Training with grouped captions}

\begin{lstlisting}[firstnumber=1,breakindent=75pt]
~/captioning/bagOfWords$ th trainingGrouped.lua --help
Usage: th [options] 

Training of the RNN network for generating image captions initialized with bag of words from all the image captions.

Options
-captionFile    JSON file with the input data (captions, image names). [~/COCO/captions_train2014.json]
-imageDirectory Directory with the images with names according to the caption file. [~/COCO/train2014/]

-pretrainedRNN  Path to a pretrained RNN. [~/RNN/2.0000__3x300.torch]

-rnnLayers      If no RNN is provided, number of recurrent layers while creating RNN. (At least one.) [3]
-rnnHidden      If no RNN is provided, number of units in hidden layers while creating RNN. (At least one.) [300]
-rnnDropout     If no RNN is provided, use dropout while creating RNN. [false]

-initLayers     How many reccurent layers initialize with CNN data. (0 - all of them) [0]
-batchSize      Minibatch size. [15]
-printError     Print error once per N minibatches. [10]
-sample         Try to sample once per N minibatches. [100]
-saveModel      Save model once per N minibatches. [10000]
-modelName      File name of the saved or loaded model and training data. [model_bag.torch]
-modelDirectory Directory where to save the model. [~/combined_model/]
\end{lstlisting}

%\chapter{RelaxNG Schéma konfiguračního soboru}
%\chapter{Plakat}

